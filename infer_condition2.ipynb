{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmitalKhan/Dissertation/blob/main/infer_condition2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qg_PykDMiJsX"
      },
      "outputs": [],
      "source": [
        "This condition will not ask users what type of inference they want. It will generate inferences, and rate the uncommonness and sensitivity of the inferences."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = 'read API key'\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # GPT-3.5 & GPT-4 use GPT-2 tokenizer\n",
        "\n",
        "def count_tokens(text):\n",
        "    \"\"\"Returns the number of tokens in a given text.\"\"\"\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "def truncate_list(data_list, max_tokens):\n",
        "    \"\"\"Truncates a list to fit within a token budget.\"\"\"\n",
        "    truncated_list = []\n",
        "    token_count = 0\n",
        "    for item in data_list:\n",
        "        item_tokens = count_tokens(str(item))  # Count tokens in each item\n",
        "        if token_count + item_tokens <= max_tokens:\n",
        "            truncated_list.append(item)\n",
        "            token_count += item_tokens\n",
        "        else:\n",
        "            break\n",
        "    return truncated_list\n",
        "\n",
        "def run_prompt(prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        # model=\"gpt-3.5-turbo\",  # Changed 'engine' to 'model'\n",
        "        model=\"gpt-4o-mini\",\n",
        "        # model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1000,\n",
        "        # max_tokens=min(1000, 16385 - input_token_count)  # Ensure within token limit\n",
        "        temperature=0.7,\n",
        "        n=1, # Return only one response\n",
        "        stop=None # optional stopping sequence\n",
        "        # request_timeout = 60\n",
        "        )\n",
        "    json_response = response.choices[0].message.content.strip()\n",
        "\n",
        "    return json_response  # Convert response to Python dictionary"
      ],
      "metadata": {
        "id": "NO7r4K6ZiQ3z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PFs-jGsmVHV",
        "outputId": "97e96712-3583-43e6-828b-5e5107ec64de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "powerset2023 = pd.read_csv('/content/drive/MyDrive/Dissertation/Study 1/Powerset/powerset_by_year/allActivity_2023.csv')"
      ],
      "metadata": {
        "id": "2wo2rXSeCiPD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_inference_json(inference_data, inference_no, columns_used):\n",
        "    \"\"\"Saves the inference data to a JSON file with an automated filename.\"\"\"\n",
        "    base_dir = \"/content/drive/MyDrive/Dissertation/Study 1/Inference_data\"\n",
        "\n",
        "    # Create a descriptive filename based on inference number and columns\n",
        "    column_names = \"_\".join([col.split(\"_\")[1] for col in columns_used])\n",
        "    filename = f\"inferences_{inference_no}_{len(columns_used)}cols_{column_names}.json\"\n",
        "    output_filename = f\"{base_dir}/{filename}\"\n",
        "\n",
        "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(inference_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"✅ JSON saved successfully as {output_filename}\")"
      ],
      "metadata": {
        "id": "fQVZahjI1hr1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns with less than 600 non-NaN rows\n",
        "misc_columns = powerset2023.columns[powerset2023.notna().sum() < 600]\n",
        "\n",
        "# Combine values into a new column\n",
        "powerset2023['takeout1_misc_MyActivity_Search Title'] = powerset2023[misc_columns].apply(\n",
        "    lambda row: ', '.join(row.dropna().astype(str)),\n",
        "    axis=1)\n",
        "\n",
        "# Drop the identified misc_columns\n",
        "powerset2023 = powerset2023.drop(columns=misc_columns)\n",
        "\n",
        "\n",
        "# Drop duplicate values in the specified column, keeping the first occurrence\n",
        "powerset2023 = powerset2023.drop_duplicates(subset=['takeout1_chrome_MyActivity_Search Title'], keep='first')"
      ],
      "metadata": {
        "id": "7UyVcx9OPmrg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make prompt more dynamic --> ask for user input for inference and recommendation #\n",
        "\n",
        "*prompt: recommend one product based on these three inferences*\n",
        "\n",
        "make numeric instead of text --> parameterize the model --> multiply it out --> if you recommend one product based on the inferences; for example inference 1 recommendation 1, inference 1 recommendation 2 and so on"
      ],
      "metadata": {
        "id": "b9K6g48ZC-ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask to select any four column\n",
        "print(\"\\nPlease select four datasets from the options (datasets should not be the same):\")\n",
        "for i, col in enumerate(powerset2023.columns, 1):\n",
        "    print(f\"{i}. {col}\")\n",
        "\n",
        "# Ask the user to select any 4 columns\n",
        "selected_columns = []\n",
        "df_selected = pd.DataFrame()\n",
        "while len(selected_columns) < 4:\n",
        "    try:\n",
        "        col_num = int(input(f\"\\nSelect column {len(selected_columns) + 1} by number (1-{len(powerset2023.columns)}): \"))\n",
        "        if 1 <= col_num <= len(powerset2023.columns):\n",
        "            col_name = powerset2023.columns[col_num - 1]\n",
        "            if col_name not in selected_columns:\n",
        "                selected_columns.append(col_name)\n",
        "            else:\n",
        "                print(\"You've already selected this column. Try another.\")\n",
        "        else:\n",
        "            print(\"Invalid number. Please choose a number from the list.\")\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "# Extract the selected columns\n",
        "powerSubset2023 = powerset2023[selected_columns]\n",
        "\n",
        "# Print the selected DataFrame\n",
        "print(\"\\nSelected DataFrame:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxDLyhx6PGBK",
        "outputId": "db946675-72ac-4632-b7bd-c5cc2072e6ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Please select four datasets from the options (datasets should not be the same):\n",
            "1. takeout1_imageSearch_MyActivity_Search Title\n",
            "2. takeout1_chrome_MyActivity_Search Title\n",
            "3. takeout1_maps_MyActivity_Search Title\n",
            "4. takeout1_YT_search-history_Search Title\n",
            "5. takeout1_YT_watch-history_Search Title\n",
            "6. takeout1_misc_MyActivity_Search Title\n",
            "\n",
            "Select column 1 by number (1-6): 1\n",
            "\n",
            "Select column 2 by number (1-6): 2\n",
            "\n",
            "Select column 3 by number (1-6): 4\n",
            "\n",
            "Select column 4 by number (1-6): 6\n",
            "\n",
            "Selected DataFrame:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Optionally, save to a CSV file\n",
        "save_option = input(\"\\nWould you like to save this selection to a CSV file? (yes/no): \").strip().lower()\n",
        "if save_option == \"yes\":\n",
        "    df_selected.to_csv(\"/content/drive/MyDrive/Dissertation/Study 1/Inference_data/24APRIL2025/chrome_maps_YTwatch_misc.csv\", index=False)\n",
        "    # print(\"File saved as 'selected_input_data.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VvySh6B6C1z",
        "outputId": "8dd82435-461d-42c5-c004-151d05e8da06"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Would you like to save this selection to a CSV file? (yes/no): no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask to select how many inferences they wat\n",
        "\n",
        "# Define the options\n",
        "options = [3,6,9,12]\n",
        "\n",
        "# Display the options\n",
        "print(\"Please select a number from the options below by typing the corresponding number:\\n\")\n",
        "for i, option in enumerate(options, 1):\n",
        "    print(f\"{i}. {option}\")\n",
        "\n",
        "# Get user input\n",
        "user_input = input(\"\\nEnter your selection (1-4): \")\n",
        "\n",
        "# Validate input\n",
        "if user_input.isdigit() and 1 <= int(user_input) <= 4:\n",
        "    inference_no = options[int(user_input) - 1]\n",
        "    print(f\"\\nYou selected: {inference_no}\")\n",
        "else:\n",
        "    print(\"\\nInvalid selection. Please enter a number between 1 and 4.\")\n",
        "\n",
        "# inference_input = int(inference_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Y43axPSFXV",
        "outputId": "f0542c20-d829-450e-db2d-05f1e5741215"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select a number from the options below by typing the corresponding number:\n",
            "\n",
            "1. 3\n",
            "2. 6\n",
            "3. 9\n",
            "4. 12\n",
            "\n",
            "Enter your selection (1-4): 1\n",
            "\n",
            "You selected: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_json_string(json_string):\n",
        "  \"\"\"Cleans a JSON string by removing unwanted characters and standardizing spacing.\"\"\"\n",
        "\n",
        "  # cleaned = re.sub(r\"```json \", \"\", json_string)\n",
        "  # Replace extra spaces and newlines with single spaces\n",
        "  cleaned = re.sub(r\"```json|```\", \" \", json_string)\n",
        "  # Remove characters outside the basic multilingual plane\n",
        "  cleaned = re.sub(r\"[^\\u0000-\\uFFFF]\", \"\", cleaned)\n",
        "  # Try to parse the cleaned JSON; return original if invalid\n",
        "  try:\n",
        "    return json.loads(cleaned)\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Warning: Failed to parse JSON, returning original: {json_string[:50]}...\")\n",
        "    return cleaned\n",
        "\n",
        "# Apply the function to each item in your list"
      ],
      "metadata": {
        "id": "TUR2HR-8DnM3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompts_for_columns(powerSubset2023, col_names, index, inference_no, num_cols=4, rows=200):\n",
        "    \"\"\"\n",
        "    Generate prompts for combinations of columns (2, 3, or 4).\n",
        "    \"\"\"\n",
        "    inference_json_list = []\n",
        "\n",
        "    # Outer loop keeps col_names[index] constant\n",
        "\n",
        "    for index in range(len(col_names) - (num_cols - 1)):\n",
        "        for next_index in range(index + 1, len(col_names) - (num_cols - 1)):\n",
        "            # Select dynamic number of columns\n",
        "            selected_cols = [col_names[index]] + col_names[next_index:next_index + (num_cols - 1)]\n",
        "\n",
        "            columns_str = \" AND \".join(selected_cols)\n",
        "\n",
        "            # Fetch data for each column\n",
        "            col_data_list = [powerSubset2023[:rows][col] for col in selected_cols]\n",
        "\n",
        "            col_data_str = \" AND \".join(\n",
        "                f\"{col_data.dropna().tolist()} in {col_name}\"\n",
        "                for col_data, col_name in zip(col_data_list, selected_cols)\n",
        "            )\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            User wants to know what {col_data_str} tells about them.\n",
        "            1. {inference_no} inferences about the user based on their online behavior in the form \"interested in X\".\n",
        "            2. For each interest, rate uncommonness of the interest (scale 1-10, where 1 = most uncommon and 10 = most common).\n",
        "            Uncommon refers to how rare or atypical an interest is among people who share similar demographic characteristics.\n",
        "            3. For each interest, rate sensitivity of interest (scale 1–10, where 1 = least sensitive and 10 = most sensitive).\n",
        "            Sensitivity refers to how likely an interest is to reveal personal, private, or stigmatized information about the user —\n",
        "            especially information they may not want to be shared, inferred, or acted upon without their consent.\n",
        "            It includes how much harm, discomfort, or unwanted exposure could result from the disclosure of that interest.\n",
        "            4. Recommend **EXACTLY ONE** product for *EACH GROUP* identified in step 2.\n",
        "            5. Recommend **EXACTLY ONE** product based on the **combination of all {inference_no} inferences** for **{columns_str}**.\n",
        "\n",
        "            **STRICT JSON OUTPUT FORMAT (No extra text or explanations, just JSON):**\n",
        "\n",
        "            ```json\n",
        "            {{\n",
        "              \"columns\": \"{columns_str}\",\n",
        "              \"inferences\": [\n",
        "                {', '.join([json.dumps({\n",
        "                    \"inference\": f\"<output for inference {{i+1}}>\",\n",
        "                    \"explanation_inference\": f\"<explanation for inference {{i+1}}>\",\n",
        "                    \"commonness\": f\"<Inference {{i+1}} commonness score>\",\n",
        "                    \"explanation_commonness\": f\"<Explanation for commonness score {{i+1}}>\",\n",
        "                    \"sensitivity\": f\"<Inference {{i+1}} sensitivity score>\",\n",
        "                    \"explanation_sensitivity\": f\"<Explanation for sensitivity score {{i+1}}>\",\n",
        "                    \"recommendation\": f\"<recommendation for inference {{i+1}}>\"\n",
        "                    }) for i in range(inference_no)])}\n",
        "                    ],\n",
        "            \"final_product_recommendation\": {{\n",
        "              \"ONE recommendation based on ALL inferences\": \"<Product name and company>\"\n",
        "              }}\n",
        "            }}\n",
        "          ```\n",
        "\"\"\"\n",
        "        # ✅ Send prompt to GPT and collect response\n",
        "        print(f\"🔹 Sending prompt to GPT for columns: {columns_str}...\")\n",
        "        assistant_reply = run_prompt(prompt)\n",
        "        print(assistant_reply)\n",
        "        inference_json_list.append(assistant_reply)\n",
        "\n",
        "    # ✅ Increment index only after inner loop finishes\n",
        "    index += 1\n",
        "\n",
        "    return inference_json_list\n"
      ],
      "metadata": {
        "id": "kW-ffxgQ-_zq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = list(powerSubset2023.columns)"
      ],
      "metadata": {
        "id": "Bf62lXqvCgn_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For 2-column combos\n",
        "inference_c2_json = build_prompts_for_columns(powerSubset2023, col_names, index=0, inference_no=3, num_cols=2)\n",
        "\n",
        "# For 4-column combos\n",
        "inference_c4_json = build_prompts_for_columns(powerSubset2023, col_names, index=0, inference_no=3, num_cols=4)\n",
        "\n",
        "# For 3-column combos\n",
        "inference_c3_json = build_prompts_for_columns(powerSubset2023, col_names, index=0, inference_no=3, num_cols=3)"
      ],
      "metadata": {
        "id": "IA6WEyQWITAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_json(output_filename, inference_json):\n",
        "    if not inference_json:\n",
        "        print(\"⚠️ No data to write. JSON file not created.\")\n",
        "        return None\n",
        "\n",
        "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(inference_json, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"✅ JSON saved successfully as {output_filename}\")\n",
        "    return output_filename"
      ],
      "metadata": {
        "id": "j11UlxyvTAlN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename_ = \"/content/drive/MyDrive/Dissertation/Study 1/Inference_data/.json\" # Define a suitable filename\n",
        "write_json(output_filename_, [clean_json_string(item) for item in inference_c2_json])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "2udruheWIq-8",
        "outputId": "febc1499-0f4a-447b-a66d-8d5fae220d83"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ JSON saved successfully as /content/drive/MyDrive/Dissertation/Study 1/Inference_data/c2_inferences.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Dissertation/Study 1/Inference_data/c2_inferences.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask LLM while generating or retrospectively to rate each of these inferences as a level of uncommonness. Add a column with inference score of 1 to 10 for uncommonness. Higher score to uncommon inferences than some of the others.\n",
        "\n",
        "Pick top N of the uncommon (unexpected), sensitive ones (including combinations) and use them\n",
        "\n",
        "Robustness in repitition and generalizabiliy"
      ],
      "metadata": {
        "id": "ck6nNzOeHPTT"
      }
    }
  ]
}