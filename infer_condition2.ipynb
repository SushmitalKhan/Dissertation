{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmitalKhan/Dissertation/blob/main/infer_condition2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qg_PykDMiJsX"
      },
      "outputs": [],
      "source": [
        "This condition will not ask users what type of inference they want. It will generate inferences, and rate the uncommonness and sensitivity of the inferences."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = ''\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # GPT-3.5 & GPT-4 use GPT-2 tokenizer\n",
        "\n",
        "def count_tokens(text):\n",
        "    \"\"\"Returns the number of tokens in a given text.\"\"\"\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "def truncate_list(data_list, max_tokens):\n",
        "    \"\"\"Truncates a list to fit within a token budget.\"\"\"\n",
        "    truncated_list = []\n",
        "    token_count = 0\n",
        "    for item in data_list:\n",
        "        item_tokens = count_tokens(str(item))  # Count tokens in each item\n",
        "        if token_count + item_tokens <= max_tokens:\n",
        "            truncated_list.append(item)\n",
        "            token_count += item_tokens\n",
        "        else:\n",
        "            break\n",
        "    return truncated_list\n",
        "\n",
        "def run_prompt(prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        # model=\"gpt-3.5-turbo\",  # Changed 'engine' to 'model'\n",
        "        model=\"gpt-4o-mini\",\n",
        "        # model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1000,\n",
        "        # max_tokens=min(1000, 16385 - input_token_count)  # Ensure within token limit\n",
        "        temperature=0.7,\n",
        "        n=1, # Return only one response\n",
        "        stop=None # optional stopping sequence\n",
        "        # request_timeout = 60\n",
        "        )\n",
        "    json_response = response.choices[0].message.content.strip()\n",
        "\n",
        "    return json_response  # Convert response to Python dictionary"
      ],
      "metadata": {
        "id": "NO7r4K6ZiQ3z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import json\n",
        "import datetime\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "4PFs-jGsmVHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "powerset2023 = pd.read_csv('/content/drive/MyDrive/Dissertation/Study 1/Powerset/powerset_by_year/allActivity_2023.csv')"
      ],
      "metadata": {
        "id": "2wo2rXSeCiPD"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns with less than 600 non-NaN rows\n",
        "misc_columns = powerset2023.columns[powerset2023.notna().sum() < 600]\n",
        "\n",
        "# Combine values into a new column\n",
        "powerset2023['takeout1_misc_MyActivity_Search Title'] = powerset2023[misc_columns].apply(\n",
        "    lambda row: ', '.join(row.dropna().astype(str)),\n",
        "    axis=1)\n",
        "\n",
        "# Drop the identified misc_columns\n",
        "powerset2023 = powerset2023.drop(columns=misc_columns)\n",
        "\n",
        "\n",
        "# Drop duplicate values in the specified column, keeping the first occurrence\n",
        "powerset2023 = powerset2023.drop_duplicates(subset=['takeout1_chrome_MyActivity_Search Title'], keep='first')\n",
        "\n",
        "powerset2023 = powerset2023.rename(columns={\n",
        "    \"old_header2\": \"new_name2\",\n",
        "    \"takeout1_imageSearch_MyActivity_Search Title\" : \"Image_Search\",\n",
        "    \"takeout1_chrome_MyActivity_Search Title\" : \"Browser_history\",\n",
        "    \"takeout1_maps_MyActivity_Search Title\" : \"Location_history\",\n",
        "    \"takeout1_YT_search-history_Search Title\" : \"YT_search_history\",\n",
        "    \"takeout1_YT_watch-history_Search Title\" : \"YT_watch_history\",\n",
        "    \"takeout1_misc_MyActivity_Search Title\" : \"Misc\"\n",
        "    })"
      ],
      "metadata": {
        "id": "7UyVcx9OPmrg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make prompt more dynamic --> ask for user input for inference and recommendation #\n",
        "\n",
        "*prompt: recommend one product based on these three inferences*\n",
        "\n",
        "make numeric instead of text --> parameterize the model --> multiply it out --> if you recommend one product based on the inferences; for example inference 1 recommendation 1, inference 1 recommendation 2 and so on"
      ],
      "metadata": {
        "id": "b9K6g48ZC-ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask to select any four column\n",
        "print(\"\\nPlease select four datasets from the options (datasets should not be the same):\")\n",
        "for i, col in enumerate(powerset2023.columns, 1):\n",
        "    print(f\"{i}. {col}\")\n",
        "\n",
        "# Ask the user to select any 4 columns\n",
        "selected_columns = []\n",
        "df_selected = pd.DataFrame()\n",
        "while len(selected_columns) < 4:\n",
        "    try:\n",
        "        col_num = int(input(f\"\\nSelect column {len(selected_columns) + 1} by number (1-{len(powerset2023.columns)}): \"))\n",
        "        if 1 <= col_num <= len(powerset2023.columns):\n",
        "            col_name = powerset2023.columns[col_num - 1]\n",
        "            if col_name not in selected_columns:\n",
        "                selected_columns.append(col_name)\n",
        "            else:\n",
        "                print(\"You've already selected this column. Try another.\")\n",
        "        else:\n",
        "            print(\"Invalid number. Please choose a number from the list.\")\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "# Extract the selected columns\n",
        "powerSubset2023 = powerset2023[selected_columns]\n",
        "\n",
        "# Print the selected DataFrame\n",
        "print(\"\\nSelected DataFrame:\")"
      ],
      "metadata": {
        "id": "CxDLyhx6PGBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Optionally, save to a CSV file\n",
        "save_option = input(\"\\nWould you like to save this selection to a CSV file? (yes/no): \").strip().lower()\n",
        "if save_option == \"yes\":\n",
        "    df_selected.to_csv(\"/content/drive/MyDrive/Dissertation/Study 1/Inference_data/24APRIL2025/chrome_maps_YTwatch_misc.csv\", index=False)\n",
        "    # print(\"File saved as 'selected_input_data.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VvySh6B6C1z",
        "outputId": "8dd82435-461d-42c5-c004-151d05e8da06"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Would you like to save this selection to a CSV file? (yes/no): no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask to select how many inferences they wat\n",
        "\n",
        "# Define the options\n",
        "options = [3,6,9,12]\n",
        "\n",
        "# Display the options\n",
        "print(\"Please select a number from the options below by typing the corresponding number:\\n\")\n",
        "for i, option in enumerate(options, 1):\n",
        "    print(f\"{i}. {option}\")\n",
        "\n",
        "# Get user input\n",
        "user_input = input(\"\\nEnter your selection (1-4): \")\n",
        "\n",
        "# Validate input\n",
        "if user_input.isdigit() and 1 <= int(user_input) <= 4:\n",
        "    inference_no = options[int(user_input) - 1]\n",
        "    print(f\"\\nYou selected: {inference_no}\")\n",
        "else:\n",
        "    print(\"\\nInvalid selection. Please enter a number between 1 and 4.\")\n",
        "\n",
        "# inference_input = int(inference_input)"
      ],
      "metadata": {
        "id": "08Y43axPSFXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_json_string(json_string):\n",
        "  \"\"\"Cleans a JSON string by removing unwanted characters and standardizing spacing.\"\"\"\n",
        "\n",
        "  # cleaned = re.sub(r\"```json \", \"\", json_string)\n",
        "  # Replace extra spaces and newlines with single spaces\n",
        "  cleaned = re.sub(r\"```json|```\", \" \", json_string)\n",
        "  # Remove characters outside the basic multilingual plane\n",
        "  cleaned = re.sub(r\"[^\\u0000-\\uFFFF]\", \"\", cleaned)\n",
        "  # Try to parse the cleaned JSON; return original if invalid\n",
        "  try:\n",
        "    return json.loads(cleaned)\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Warning: Failed to parse JSON, returning original: {json_string[:50]}...\")\n",
        "    return cleaned\n",
        "\n",
        "# Apply the function to each item in your list"
      ],
      "metadata": {
        "id": "TUR2HR-8DnM3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "def build_prompts_for_user_combinations(\n",
        "    powerSubset2023,        # DataFrame with user-selected columns\n",
        "    inference_no,           # number of inferences per prompt\n",
        "    rows,                   # number of rows to sample from each dataset\n",
        "    combo_sizes,            # int or list/tuple of combination sizes\n",
        "    folder=\"outputs\"        # folder to save JSON\n",
        "):\n",
        "    \"\"\"\n",
        "    Build prompts for all possible combinations of columns in the DataFrame\n",
        "    for the specified combination sizes.\n",
        "    \"\"\"\n",
        "\n",
        "    # If user passes a single integer, convert to a list\n",
        "    if isinstance(combo_sizes, int):\n",
        "        combo_sizes = [combo_sizes]\n",
        "\n",
        "    col_names = list(powerSubset2023.columns)\n",
        "    inference_json_list = []\n",
        "\n",
        "    for combo_size in combo_sizes:\n",
        "        # skip invalid sizes\n",
        "        if combo_size < 1 or combo_size > len(col_names):\n",
        "            print(f\"‚ö†Ô∏è Skipping invalid combination size: {combo_size}\")\n",
        "            continue\n",
        "\n",
        "        # generate all combinations of the specified size\n",
        "        all_combos = list(itertools.combinations(col_names, combo_size))\n",
        "\n",
        "        for selected_cols in all_combos:\n",
        "            columns_str = \" AND \".join(selected_cols)\n",
        "\n",
        "            # fetch data for each column\n",
        "            col_data_list = [powerSubset2023[:rows][col] for col in selected_cols]\n",
        "            col_data_str = \" AND \".join(\n",
        "                f\"{col_data.dropna().tolist()} in {col_name}\"\n",
        "                for col_data, col_name in zip(col_data_list, selected_cols)\n",
        "            )\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            User wants to know what {col_data_str} tells about them.\n",
        "            1. {inference_no} inferences about the user based on their online behavior in the form \"interested in X\".\n",
        "            2. Rate uncommonness (1‚Äì10) and sensitivity (1‚Äì10) for each inference.\n",
        "            3. Recommend **EXACTLY ONE** product for each group.\n",
        "            4. Recommend **EXACTLY ONE** product based on all {inference_no} inferences for {columns_str}.\n",
        "\n",
        "            STRICT JSON OUTPUT ONLY.\n",
        "            \"\"\"\n",
        "\n",
        "            print(f\"üîπ Sending prompt to GPT for columns: {columns_str}...\")\n",
        "            assistant_reply = run_prompt(prompt)\n",
        "\n",
        "            inference_json_list.append({\n",
        "                \"combined_cols\": selected_cols,\n",
        "                \"combo_size\": combo_size,\n",
        "                \"gpt_output\": assistant_reply\n",
        "            })\n",
        "\n",
        "    # Save JSON\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"inferences_user_combinations_{timestamp}.json\"\n",
        "    filepath = Path(folder) / filename\n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    return inference_json_list, filepath\n"
      ],
      "metadata": {
        "id": "kW-ffxgQ-_zq"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_json, output_file = build_prompts_for_user_combinations(\n",
        "    powerSubset2023,\n",
        "    inference_no= inference_no,\n",
        "    rows= 200, #Update number of rows to the full dataset\n",
        "    combo_sizes= [1,2,3,4],\n",
        "    folder=\"/content/drive/MyDrive/Dissertation/Study 1/Inference_data/\"\n",
        ")"
      ],
      "metadata": {
        "id": "Bf62lXqvCgn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_json(output_filename, inference_json):\n",
        "    if not inference_json:\n",
        "        print(\"‚ö†Ô∏è No data to write. JSON file not created.\")\n",
        "        return None\n",
        "\n",
        "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(inference_json, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"‚úÖ JSON saved successfully as {output_filename}\")\n",
        "    return output_filename"
      ],
      "metadata": {
        "id": "F7JWekn1euNo"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply clean_json_string to GPT outputs only\n",
        "for entry in inference_json:\n",
        "    if isinstance(entry.get(\"gpt_output\"), str):\n",
        "        entry[\"gpt_output\"] = clean_json_string(entry[\"gpt_output\"])"
      ],
      "metadata": {
        "id": "hBEZT3sX4df-"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_json(\n",
        "    output_file, inference_json\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RapP9X2flbVn",
        "outputId": "cfc79055-6834-4715-f50a-8b14023d3cdd"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ JSON saved successfully as /content/drive/MyDrive/Dissertation/Study 1/Inference_data/inferences_user_combinations_20250911_222951.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/Dissertation/Study 1/Inference_data/inferences_user_combinations_20250911_222951.json')"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask LLM while generating or retrospectively to rate each of these inferences as a level of uncommonness. Add a column with inference score of 1 to 10 for uncommonness. Higher score to uncommon inferences than some of the others.\n",
        "\n",
        "Pick top N of the uncommon (unexpected), sensitive ones (including combinations) and use them\n",
        "\n",
        "Robustness in repitition and generalizabiliy"
      ],
      "metadata": {
        "id": "ck6nNzOeHPTT"
      }
    }
  ]
}