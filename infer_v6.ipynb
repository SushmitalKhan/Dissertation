{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushmitalKhan/Dissertation/blob/main/infer_v6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Qg_PykDMiJsX"
      },
      "outputs": [],
      "source": [
        "# !pip install openai\n",
        "# !pip install --force-reinstall -v openai==1.55.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = 'read_api_key'\n",
        "\n",
        "def count_tokens(text):\n",
        "    \"\"\"Returns the number of tokens in a given text.\"\"\"\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "def truncate_list(data_list, max_tokens):\n",
        "    \"\"\"Truncates a list to fit within a token budget.\"\"\"\n",
        "    truncated_list = []\n",
        "    token_count = 0\n",
        "    for item in data_list:\n",
        "        item_tokens = count_tokens(str(item))  # Count tokens in each item\n",
        "        if token_count + item_tokens <= max_tokens:\n",
        "            truncated_list.append(item)\n",
        "            token_count += item_tokens\n",
        "        else:\n",
        "            break\n",
        "    return truncated_list\n",
        "\n",
        "def run_prompt(prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=1000,\n",
        "        temperature=0.7,\n",
        "        n=1, # Return only one response\n",
        "        stop=None # optional stopping sequence\n",
        "        # request_timeout = 60\n",
        "        )\n",
        "    json_response = response.choices[0].message.content.strip()\n",
        "\n",
        "    return json_response  # Convert response to Python dictionary"
      ],
      "metadata": {
        "id": "NO7r4K6ZiQ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PFs-jGsmVHV",
        "outputId": "d5e9579a-8320-45c7-def4-cd2eb8ddb35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "powerset2023 = pd.read_csv('/content/drive/MyDrive/Dissertation/Study 1/Powerset/powerset_by_year/allActivity_2023.csv')"
      ],
      "metadata": {
        "id": "2wo2rXSeCiPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select columns with less than 600 non-NaN rows\n",
        "misc_columns = powerset2023.columns[powerset2023.notna().sum() < 600]\n",
        "\n",
        "# Combine values into a new column\n",
        "powerset2023['takeout1_misc_MyActivity_Search Title'] = powerset2023[misc_columns].apply(\n",
        "    lambda row: ', '.join(row.dropna().astype(str)),\n",
        "    axis=1)\n",
        "\n",
        "# Drop the identified misc_columns\n",
        "powerset2023 = powerset2023.drop(columns=misc_columns)\n",
        "\n",
        "\n",
        "# Drop duplicate values in the specified column, keeping the first occurrence\n",
        "powerset2023 = powerset2023.drop_duplicates(subset=['takeout1_chrome_MyActivity_Search Title'], keep='first')\n",
        "\n",
        "# drop_nan_ = powerset2023.dropna(how='all')\n",
        "# print(drop_nan_.count())\n",
        "\n",
        "# powerset2023_copy = powerset2023.copy()"
      ],
      "metadata": {
        "id": "ILeYZi3iThQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make prompt more dynamic --> ask for user input for inference and recommendation #\n",
        "\n",
        "*prompt: recommend one product based on these three inferences*\n",
        "\n",
        "make numeric instead of text --> parameterize the model --> multiply it out --> if you recommend one product based on the inferences; for example inference 1 recommendation 1, inference 1 recommendation 2 and so on"
      ],
      "metadata": {
        "id": "b9K6g48ZC-ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask to select any four column\n",
        "\n",
        "print(\"\\nAvailable columns:\")\n",
        "for i, col in enumerate(powerset2023.columns, 1):\n",
        "    print(f\"{i}. {col}\")\n",
        "\n",
        "# Ask the user to select any 4 columns\n",
        "selected_columns = []\n",
        "df_selected = pd.DataFrame()\n",
        "while len(selected_columns) < 4:\n",
        "    try:\n",
        "        col_num = int(input(f\"\\nSelect column {len(selected_columns) + 1} by number (1-{len(powerset2023.columns)}): \"))\n",
        "        if 1 <= col_num <= len(powerset2023.columns):\n",
        "            col_name = powerset2023.columns[col_num - 1]\n",
        "            if col_name not in selected_columns:\n",
        "                selected_columns.append(col_name)\n",
        "            else:\n",
        "                print(\"You've already selected this column. Try another.\")\n",
        "        else:\n",
        "            print(\"Invalid number. Please choose a number from the list.\")\n",
        "    except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "# Extract the selected columns\n",
        "powerSubset2023 = powerset2023[selected_columns]\n",
        "\n",
        "# Print the selected DataFrame\n",
        "print(\"\\nSelected DataFrame:\")\n",
        "# print(powerSubset2023)\n",
        "\n",
        "# # Optionally, save to a CSV file\n",
        "save_option = input(\"\\nWould you like to save this selection to a CSV file? (yes/no): \").strip().lower()\n",
        "if save_option == \"yes\":\n",
        "    df_selected.to_csv(\"/content/drive/MyDrive/Dissertation/Study 1/Inference_data/AUGUST2025/9SEP25_image_chrome_YTsearch_misc.csv\", index=False)\n",
        "    # print(\"File saved as 'selected_input_data.csv'.\")"
      ],
      "metadata": {
        "id": "t3qu_AnC_zG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask to select how many inferences they wat\n",
        "\n",
        "# Define the options\n",
        "options = [3,6,9,12]\n",
        "\n",
        "# Display the options\n",
        "print(\"Please select a number from the options below by typing the corresponding number:\\n\")\n",
        "for i, option in enumerate(options, 1):\n",
        "    print(f\"{i}. {option}\")\n",
        "\n",
        "# Get user input\n",
        "user_input = input(\"\\nEnter your selection (1-4): \")\n",
        "\n",
        "# Validate input\n",
        "if user_input.isdigit() and 1 <= int(user_input) <= 4:\n",
        "    inference_no = options[int(user_input) - 1]\n",
        "    print(f\"\\nYou selected: {inference_no}\")\n",
        "else:\n",
        "    print(\"\\nInvalid selection. Please enter a number between 1 and 4.\")\n",
        "\n",
        "# inference_input = int(inference_input)"
      ],
      "metadata": {
        "id": "Vq59Y1wirHu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6pLsZ-qAkzxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for the combination of the three inferences for the combination of the three inferences\n",
        "when categorizing --> ask to filter 15 to 25 percent of the data that you think are the most sensitive, interesting, or different from the rest. then categorize the rest of them --> find interesting without losing the context"
      ],
      "metadata": {
        "id": "O3jFIZevk2Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize list to store responses\n",
        "inference_c0_json = []\n",
        "\n",
        "# Iterate through each column in power_subset1_\n",
        "for col_name, col_data in powerSubset2023[:1500].items():\n",
        "  # print(col_data.dropna().tolist())\n",
        "  # Define the strict JSON prompt\n",
        "\n",
        "  prompt = f\"\"\"User wants to know what {col_data.dropna().tolist()} in {col_name} tells about them.\n",
        "  1. {inference_no} inferences about the user based on their online behavior in the form \"interested in X\".\n",
        "  2. Recommend **EXACTLY ONE** product for *EACH* inferences from step 1\n",
        "  3. Recommend **EXACTLY ONE** product based on the **combination of all {inference_no} inferences** for **{col_name}**.\n",
        "   **STRICT JSON OUTPUT FORMAT (No extra text or explanations, just JSON):**\n",
        "   ```json\n",
        "   {{\n",
        "    \"columns\": \"{col_name}\",\n",
        "    \"inferences\": [\n",
        "    {', '.join([json.dumps({\n",
        "      \"inference\": f\"<output for inference {i+1}>\",\n",
        "      \"explanation_inference\": f\"<explanation for inference {i+1}>\",\n",
        "      \"recommendation\": f\"<recommendation for inference {i+1}>\"\n",
        "    }) for i in range(inference_no)])}\n",
        "    ],\n",
        "    \"final_product_recommendation\": {{\n",
        "      \"ONE recommendation based on ALL inferences\": \"<Product name and company>\",\n",
        "    }}\n",
        "   }}\n",
        "   ```\n",
        "  }}\"\"\"\n",
        "\n",
        "  print(f\"🔹 Sending prompt to GPT for column: {col_name}...\")\n",
        "  assistant_reply = run_prompt(prompt)\n",
        "  print(prompt)\n",
        "\n",
        "  if assistant_reply:\n",
        "    # Remove unwanted code block markers\n",
        "    cleaned_json = re.sub(r\"```json\\s*|\\s*```\", \"\", assistant_reply).strip()\n",
        "\n",
        "    try:\n",
        "      # Parse JSON\n",
        "      parsed_json = json.loads(cleaned_json)\n",
        "      inference_c0_json.append(parsed_json)  # Store parsed data\n",
        "    except json.JSONDecodeError:\n",
        "      print(f\"⚠️ JSON Decoding Error. Skipping entry:\\n{cleaned_json[:100]}...\")  # Preview problematic JSON\n"
      ],
      "metadata": {
        "id": "5aE9sD2U41E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_c2 = []\n",
        "inference_c2_json = []\n",
        "\n",
        "index = 0  # Keeps col_name[index] constant\n",
        "col_names = list(powerSubset2023[:1500].columns)  # Convert column names to a list\n",
        "\n",
        "while index < len(col_names):  # Outer loop for the constant column\n",
        "    for next_index in range(index + 1, len(col_names)):  # Inner loop for incrementing column\n",
        "        # Fetch data for the columns\n",
        "        col_data_1 = powerSubset2023[:1500][col_names[index]]\n",
        "        col_data_2 = powerSubset2023[:1500][col_names[next_index]]\n",
        "\n",
        "        # Define the prompt\n",
        "        prompt = f\"\"\"user wants to know what {col_data_1.dropna().tolist()} in {col_names[index]} and {col_data_2.dropna().tolist()} in {col_names[next_index]} tells about them as per the following:\n",
        "        1. {user_input} inferences based on users online behavior in the form interested in X (where X is a single interest) for each column.\n",
        "        2. Recommend **EXACTLY ONE** product for *EACH* inferences from step 1\n",
        "        3. Recommend **EXACTLY ONE** product based on the **combination of all {inference_no} inferences** for **{col_names[index]} AND {col_names[next_index]}**.\n",
        "        **STRICT JSON OUTPUT FORMAT (No extra text or explanations, just JSON):**\n",
        "   ```json\n",
        "   {{\n",
        "    \"columns\": \"{col_names[index]} AND {col_names[next_index]}\",\n",
        "    \"inferences\": [\n",
        "    {', '.join([json.dumps({\n",
        "      \"inference\": f\"<output for inference {i+1}>\",\n",
        "      \"explanation_inference\": f\"<explanation for inference {i+1}>\",\n",
        "      \"recommendation\": f\"<recommendation for inference {i+1}>\"\n",
        "    }) for i in range(inference_no)])}\n",
        "    ],\n",
        "    \"final_product_recommendation\": {{\n",
        "      \"ONE recommendation based on ALL inferenceces\": \"<Product name and company>\",\n",
        "    }}\n",
        "   }}\n",
        "   ```\n",
        "  }}\n",
        "\n",
        "    **Strictly return a valid JSON object in this format. DO NOT include any other text or explanations.**\"\"\"\n",
        "\n",
        "        # Run the prompt and get the response\n",
        "        print(prompt)\n",
        "        assistant_reply = run_prompt(prompt)\n",
        "        # print(assistant_reply)\n",
        "\n",
        "        if assistant_reply:\n",
        "            # Remove unwanted code block markers\n",
        "            cleaned_json = re.sub(r\"```json\\s*|\\s*```\", \"\", assistant_reply).strip()\n",
        "\n",
        "            try:\n",
        "                # Parse JSON\n",
        "                parsed_json = json.loads(cleaned_json)\n",
        "                inference_c2_json.append(parsed_json)  # Store parsed data\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"⚠️ JSON Decoding Error. Skipping entry:\\n{cleaned_json[:100]}...\")  # Preview problematic JSON\n",
        "\n",
        "\n",
        "    # Move to the next constant column\n",
        "    index += 1"
      ],
      "metadata": {
        "id": "1l7LI1KU1vb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_c3 = []\n",
        "inference_c3_json = []\n",
        "\n",
        "index = 0  # Keeps col_name[index] constant\n",
        "col_names = list(powerSubset2023[:1500].columns)  # Convert column names to a list\n",
        "\n",
        "# Outer loop keeps col_name[index] constant\n",
        "while index < len(col_names):\n",
        "    for next_index in range(index + 1, len(col_names) - 1):  # Iterate for combinations\n",
        "        # Fetch data for the selected columns\n",
        "        col_data_1 = powerSubset2023[:1500][col_names[index]]\n",
        "        col_data_2 = powerSubset2023[:1500][col_names[next_index]]\n",
        "        col_data_3 = powerSubset2023[:1500][col_names[next_index + 1]]\n",
        "\n",
        "        # Define the prompt\n",
        "        prompt = f\"\"\"user wants to know what {col_data_1.dropna().tolist()} in {col_names[index]} combined with {col_data_2.dropna().tolist()} in {col_names[next_index]} and {col_data_3.dropna().tolist()} in {col_names[next_index + 1]} tells about them as per the following:\n",
        "        1. {user_input} inferences based on users online behavior in the form interested in X (where X is a single interest) for each column.\n",
        "        2. Recommend **EXACTLY ONE** product for *EACH* inferences from step 1\n",
        "        3. Recommend **EXACTLY ONE** product based on the **combination of all {inference_no} inferences** for **{col_names[index]} AND {col_names[next_index]} AND {col_names[next_index+1]}**.\n",
        "        **STRICT JSON OUTPUT FORMAT (No extra text or explanations, just JSON):**\n",
        "   ```json\n",
        "   {{\n",
        "    \"columns\": \"{col_names[index]} AND {col_names[next_index]} AND {col_names[next_index+1]}\",\n",
        "    \"inferences\": [\n",
        "    {', '.join([json.dumps({\n",
        "      \"inference\": f\"<output for inference {i+1}>\",\n",
        "      \"explanation_inference\": f\"<explanation for inference {i+1}>\",\n",
        "      \"recommendation\": f\"<recommendation for inference {i+1}>\"\n",
        "    }) for i in range(inference_no)])}\n",
        "    ],\n",
        "    \"final_product_recommendation\": {{\n",
        "      \"ONE recommendation based on ALL inferenceces\": \"<Product name and company>\",\n",
        "    }}\n",
        "   }}\n",
        "   ```\n",
        "  }}\n",
        "\n",
        "    **Strictly return a valid JSON object in this format. DO NOT include any other text or explanations.**\"\"\"\n",
        "\n",
        "        assistant_reply = run_prompt(prompt)\n",
        "        # print(assistant_reply)\n",
        "\n",
        "        if assistant_reply:\n",
        "            # Remove unwanted code block markers\n",
        "            cleaned_json = re.sub(r\"```json\\s*|\\s*```\", \"\", assistant_reply).strip()\n",
        "\n",
        "            try:\n",
        "                # Parse JSON\n",
        "                parsed_json = json.loads(cleaned_json)\n",
        "                inference_c3_json.append(parsed_json)  # Store parsed data\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"⚠️ JSON Decoding Error. Skipping entry:\\n{cleaned_json[:100]}...\")  # Preview problematic JSON\n",
        "\n",
        "    index += 1\n"
      ],
      "metadata": {
        "id": "pJOb7IWH1nCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_inference_json(inference_data, inference_no, columns_used):\n",
        "    \"\"\"Saves the inference data to a JSON file with an automated filename.\"\"\"\n",
        "    base_dir = \"/content/drive/MyDrive/Dissertation/Study 1/Inference_data\"\n",
        "\n",
        "    # Create a descriptive filename based on inference number and columns\n",
        "    column_names = \"_\".join([col.split(\"_\")[1] for col in columns_used])\n",
        "    filename = f\"inferences_{inference_no}_{len(columns_used)}cols_{column_names}.json\"\n",
        "    output_filename = f\"{base_dir}/{filename}\"\n",
        "\n",
        "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(inference_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"✅ JSON saved successfully as {output_filename}\")"
      ],
      "metadata": {
        "id": "Oxw8WKhP1ze3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4011df30"
      },
      "source": [
        "save_inference_json(inference_c2_json, inference_no, powerSubset2023.columns)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}